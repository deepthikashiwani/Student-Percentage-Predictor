{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student's percentage prediction\n",
    "\n",
    "In this regression task we will predict the percentage of marks that a student is expected to score based upon the number of hours they studied.\n",
    "This is a simple linear regression task as it involves just two variables.\n",
    "\n",
    "What will be predicted score if a student study for 8 hrs in a day?\n",
    "\n",
    "**Data set** : http://bit.ly/w-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from remote link\n",
    "url = \"http://bit.ly/w-data\"\n",
    "data = pd.read_csv(url)\n",
    "print(\"Data imported successfully\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning the data**\n",
    "   \n",
    "   Here, we are scouring thorough the given dataset to check out for null values. If there are none, data cleaning is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the score distribution**\n",
    "\n",
    "   Now, we plot the given dataset using a 2-D graph to eyeball our datasent and see if we can find any kind of relationship between Hours and Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of scores\n",
    "data.plot(x='Hours', y='Scores', style='o')  \n",
    "plt.title('Study Hours vs Percentage Scores')  \n",
    "plt.xlabel('Hours Studied')  \n",
    "plt.ylabel('Percentage Score')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting regressor plot to determine the relationship between feature and target\n",
    "sns.regplot(x=data['Hours'],y=data['Scores'],data=data)\n",
    "plt.title('Study Hours vs Percentage Scores')\n",
    "plt.xlabel('Study Hours')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From the graph, it is clearly proven that there is a positive linear relation between the number of hours studied and the percentage of scores.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing the data**\n",
    "\n",
    "   Now, we should define our \"attributes\" (input) variable and \"labels\" (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values  #Attribute\n",
    "y = data.iloc[:, 1].values    #Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the attributes and labels defined, the next step is to split this data into training and test sets.\n",
    "\n",
    "This is done using *Scikit-Learn's built-in train-test-split method*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scikit-Learn's built-in train_test_split() method:\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the training and testing sets are ready for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Algorithm\n",
    "\n",
    "Now,the linear regression algorithm is made from scratch and will be compared with built-in Scikit-learn's linear regression function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making the Linear Regression Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = y_train.reshape(-1,1)  \n",
    "ones = np.ones([X_train.shape[0], 1]) # create a array containing only ones \n",
    "X_train_new = np.concatenate([ones, X_train],1) # concatenate the ones to X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the theta matrix\n",
    "# notice small alpha value\n",
    "alpha = 0.01\n",
    "iters = 5000\n",
    "\n",
    "theta = np.array([[1.0, 1.0]])\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Function\n",
    "def findCost(X, y, theta):\n",
    "    inner = np.power(((X @ theta.T) - y), 2)\n",
    "    return np.sum(inner) / (2 * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findCost(X_train_new, y_train_new, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This value is the initial value. The aim is to minimise this value as small as possible.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "def gradientDescent(X, y, theta, alpha, iters):\n",
    "    m = len(X)\n",
    "    for i in range(iters):\n",
    "        theta = theta - (alpha/m) * np.sum(((X @ theta.T) - y) * X, axis=0)\n",
    "        cost = findCost(X, y, theta)\n",
    "        #if i % 10 == 0:\n",
    "            #print(cost)\n",
    "    return (theta, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, cost = gradientDescent(X_train_new, y_train_new, theta, alpha, iters)  \n",
    "print(\"Intercept -\", g[0][0])\n",
    "print(\"Coefficient- \", g[0][1])\n",
    "print(\"The final cost obtained after optimisation - \", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can clearly see that the cost before and after optimization is hugely decreased.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting scatter points\n",
    "plt.scatter(X, y, label='Scatter Plot')\n",
    "axes = plt.gca()\n",
    "\n",
    "# Plotting the Line\n",
    "x_vals = np.array(axes.get_xlim()) \n",
    "y_vals = g[0][0] + g[0][1]* x_vals #the line equation\n",
    "\n",
    "plt.plot(x_vals, y_vals, color='red', label='Regression Line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the above method was building the regression algorithm from scratch and implementing it on the data-set. However, as you can see this is in crude form, a more elegant would be to make a class of it.\n",
    "\n",
    "The hyper-parameters such \"alpha\" also known as the learning rate is optimised by hit and trial method, which should not be the practice.\n",
    "\n",
    "So, instead of writing this long code, python has an-inbuilt library for the same. This will be implemented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Scikit-Learn Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression  \n",
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train) \n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Coefficient -\", regressor.coef_)\n",
    "print (\"Intercept - \", regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the regression line\n",
    "line = regressor.coef_*X + regressor.intercept_\n",
    "\n",
    "# Plotting for the test data\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, line,color='red', label='Regression Line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is observed that both the graphs, the intercepts and coefficient of the line are identical.This proves that my linear regression algorithm is correct.\n",
    "\n",
    "But as you can see, it's a lot more easier to use the built-in function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Now that we have trained our algorithm, the next step is to make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test) # Testing data - In Hours\n",
    "y_pred = regressor.predict(X_test) # Predicting the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Actual vs Predicted\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating training and test score\n",
    "print(\"Training Score:\",regressor.score(X_train,y_train))\n",
    "print(\"Test Score:\",regressor.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the grid to depict the actual and predicted value\n",
    "df.plot(kind='bar',figsize=(7,7))\n",
    "plt.grid(which='major', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model with new data\n",
    "hours = 8\n",
    "test = np.array([hours])\n",
    "test = test.reshape(-1, 1)\n",
    "own_pred = regressor.predict(test)\n",
    "print(\"No of Hours = {}\".format(hours))\n",
    "print(\"Predicted Score = {}\".format(own_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model\n",
    "\n",
    "The final step is to evaluate the performance of the model. This step is important to compare how well both the algorithms perform on a specified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:',metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('R-2:', metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can clearly see that the **R^2 value also known as model's accuracy is 96.78%** which proves that the algorithms are working well for the given dataset.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
